FashionMnist(
  (layer): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=s)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=s)
    (2): IFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): AvgPool2d(kernel_size=2, stride=2, padding=0, step_mode=s)
    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=s)
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=s)
    (6): IFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): AvgPool2d(kernel_size=2, stride=2, padding=0, step_mode=s)
    (8): Flatten(start_dim=1, end_dim=-1, step_mode=s)
    (9): Linear(in_features=1568, out_features=512, bias=False)
    (10): IFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Linear(in_features=512, out_features=10, bias=False)
    (12): IFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
  )
)
number of params: 817568
test_loss = 0.0438, test_acc = 0.7530
test speed = 1681.7487 images/s
test_loss = 0.0438, test_acc = 0.7494
test speed = 3438.0729 images/s
Quantized:  layer
Quantized:  0
Quantized:  1
Quantized:  2
Quantized:  3
Quantized:  4
Quantized:  5
Quantized:  6
Quantized:  7
Quantized:  8
Quantized:  9
Quantized:  10
Quantized:  11
Quantized:  12
Quantization time: 0.0012054443359375
Quantization time: 0.0021042823791503906
test_loss = 0.0439, test_acc = 0.7499
test speed = 3450.2985 images/s
Constructing Axons from Conv2d Layer
Input layer shape(infeature, outfeature): [ 1 28 28] [32 28 28]
Constructing 32 bias axons from conv layer.
Numer of neurons: 0, number of axons: 816
Converting Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s) takes 0.2110915184020996
Constructing hidden avgpool layer
Hidden layer shape(infeature, outfeature): (32, 28, 28) [32 14 14]
Numer of neurons: 25088, number of axons: 816
Constructing Neurons from Conv2d Layer
Hidden layer shape(infeature, outfeature): (32, 14, 14) [32 14 14]
Constructing 32 bias axons from conv layer.
Numer of neurons: 31360, number of axons: 848
Converting Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s) takes 1.440732479095459
Constructing hidden avgpool layer
Hidden layer shape(infeature, outfeature): (32, 14, 14) [32  7  7]
Numer of neurons: 37632,   number of axons: 848
Constructing neurons from linear Layer
Hidden layer shape(infeature, outfeature):  (32, 7, 7) 512
Numer of neurons: 39200, number of axons: 848
Constructing neurons from linear Layer
Hidden layer shape(infeature, outfeature):  (512,) 10
Numer of neurons: 39712, number of axons: 848
[]
FashionMnist(
  (layer): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=s)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=s)
    (2): IFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): AvgPool2d(kernel_size=2, stride=2, padding=0, step_mode=s)
    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, step_mode=s)
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=s)
    (6): IFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): AvgPool2d(kernel_size=2, stride=2, padding=0, step_mode=s)
    (8): Flatten(start_dim=1, end_dim=-1, step_mode=s)
    (9): Linear(in_features=1568, out_features=512, bias=False)
    (10): IFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Linear(in_features=512, out_features=10, bias=False)
    (12): IFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
  )
)
number of params: 817568
test_loss = 0.0371, test_acc = 0.7728
test speed = 1642.8746 images/s
test_loss = 0.0370, test_acc = 0.7741
test speed = 3449.6868 images/s
Quantized:  layer
Quantized:  0
Quantized:  1
Quantized:  2
Quantized:  3
Quantized:  4
Quantized:  5
Quantized:  6
Quantized:  7
Quantized:  8
Quantized:  9
Quantized:  10
Quantized:  11
Quantized:  12
Quantization time: 0.0012607574462890625
Quantization time: 0.0021610260009765625
test_loss = 0.0371, test_acc = 0.7728
test speed = 3438.9055 images/s
Constructing Axons from Conv2d Layer
Input layer shape(infeature, outfeature): [ 1 28 28] [32 28 28]
Constructing 32 bias axons from conv layer.
Numer of neurons: 0, number of axons: 816
Converting Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s) takes 0.2068173885345459
Constructing hidden avgpool layer
Hidden layer shape(infeature, outfeature): (32, 28, 28) [32 14 14]
Numer of neurons: 25088, number of axons: 816
Constructing Neurons from Conv2d Layer
Hidden layer shape(infeature, outfeature): (32, 14, 14) [32 14 14]
Constructing 32 bias axons from conv layer.
Numer of neurons: 31360, number of axons: 848
Converting Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s) takes 1.3943994045257568
Constructing hidden avgpool layer
Hidden layer shape(infeature, outfeature): (32, 14, 14) [32  7  7]
Numer of neurons: 37632, number of axons: 848
Constructing neurons from linear Layer
Hidden layer shape(infeature, outfeature):  (32, 7, 7) 512
Numer of neurons: 39200, number of axons: 848
Constructing neurons from linear Layer
Hidden layer shape(infeature, outfeature):  (512,) 10
Instantiate output neurons
Numer of neurons: 39722, number of axons: 848
['39712', '39713', '39714', '39715', '39716', '39717', '39718', '39719', '39720', '39721']
