{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974271a6",
   "metadata": {},
   "source": [
    "# CRI MNIST Demonstration with snnTorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830d120",
   "metadata": {},
   "source": [
    "## Training SNN with snnTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snntorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47b541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from quant_layer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8a486",
   "metadata": {},
   "source": [
    "### Import MNIST datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f283ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader arguments\n",
    "batch_size = 128\n",
    "data_path='~/justinData/mnist'\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b1c2c",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2322fdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'surrogate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[1;32m      8\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m spike_grad \u001b[38;5;241m=\u001b[39m \u001b[43msurrogate\u001b[49m\u001b[38;5;241m.\u001b[39mfast_sigmoid(slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'surrogate' is not defined"
     ]
    }
   ],
   "source": [
    "# Network Architecture\n",
    "num_inputs = 28*28\n",
    "num_hidden_0 = 1000\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 25\n",
    "beta = 1.0\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(QuantLinear(num_inputs, num_hidden_0, bias = True), \n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad,init_hidden=True),\n",
    "                    QuantLinear(num_hidden_0, num_outputs, bias = True),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad,init_hidden=True, output=True)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e41f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = next(iter(train_loader))\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, num_steps, data, batch_size):\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "    utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        spk_out, mem_out = net(data.view(batch_size, -1))\n",
    "        spk_rec.append(spk_out)\n",
    "        mem_rec.append(mem_out)\n",
    "  \n",
    "    return torch.stack(spk_rec), torch.stack(mem_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_rec, mem_rec = forward_pass(net, num_steps, data, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07deb717",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358fb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SF.ce_rate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "print(f\"The loss from an untrained network is {loss_val.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899eecf",
   "metadata": {},
   "source": [
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c576e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = SF.accuracy_rate(spk_rec, targets)\n",
    "\n",
    "print(f\"The accuracy of a single batch using an untrained network is {acc*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net, num_steps, batch_size):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        acc = 0\n",
    "        net.eval()\n",
    "\n",
    "        train_loader = iter(train_loader)\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            spk_rec, _ = forward_pass(net, num_steps, data, batch_size)\n",
    "\n",
    "            acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "            total += spk_rec.size(1)\n",
    "\n",
    "    return acc/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab38e51",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a39c571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-3, betas=(0.9, 0.999))\n",
    "num_epochs = 20\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = forward_pass(net, num_steps, data, batch_size)\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        loss_val += loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = forward_pass(net, num_steps, test_data,batch_size)\n",
    "\n",
    "            # Test set loss\n",
    "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            test_loss += loss_fn(test_spk, test_targets)\n",
    "\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 50 == 0:\n",
    "                print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "                print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "                print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "                train_acc = SF.accuracy_rate(spk_rec, targets)\n",
    "                test_acc = SF.accuracy_rate(test_spk, test_targets)\n",
    "                print(f\"Train set accuracy for a single minibatch: {train_acc*100:.2f}%\")\n",
    "                print(f\"Test set accuracy for a single minibatch: {test_acc*100:.2f}%\")\n",
    "                print(\"\\n\")\n",
    "            counter += 1\n",
    "            iter_counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = batch_accuracy(test_loader, net, num_steps, batch_size)\n",
    "\n",
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "plt.plot(loss_hist)\n",
    "plt.plot(test_loss_hist)\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend([\"Train Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80236a",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22377313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_quan, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_quan:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_quantized_6L.pth.tar'))\n",
    "    else:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_snnTorch_6L.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2179c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa258d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({'state_dict': net.state_dict(),}, 1, fdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605f20e",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_quantization(b):\n",
    "\n",
    "    def uniform_quant(x, b):\n",
    "        xdiv = x.mul((2 ** b - 1))\n",
    "        xhard = xdiv.round().div(2 ** b - 1)\n",
    "        #print('uniform quant bit: ', b)\n",
    "        return xhard\n",
    "\n",
    "    class _pq(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, alpha):\n",
    "            input.div_(alpha)                          # weights are first divided by alpha\n",
    "            input_c = input.clamp(min=-1, max=1)       # then clipped to [-1,1]\n",
    "            sign = input_c.sign()\n",
    "            input_abs = input_c.abs()\n",
    "            input_q = uniform_quant(input_abs, b).mul(sign)\n",
    "            ctx.save_for_backward(input, input_q)\n",
    "            input_q = input_q.mul(alpha)               # rescale to the original range\n",
    "            return input_q\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            grad_input = grad_output.clone()             # grad for weights will not be clipped\n",
    "            input, input_q = ctx.saved_tensors\n",
    "            i = (input.abs()>1.).float()     # >1 means clipped. # output matrix is a form of [True, False, True, ...]\n",
    "            sign = input.sign()              # output matrix is a form of [+1, -1, -1, +1, ...]\n",
    "            #grad_alpha = (grad_output*(sign*i + (input_q-input)*(1-i))).sum()\n",
    "            grad_alpha = (grad_output*(sign*i + (0.0)*(1-i))).sum()\n",
    "            # above line, if i = True,  and sign = +1, \"grad_alpha = grad_output * 1\"\n",
    "            #             if i = False, \"grad_alpha = grad_output * (input_q-input)\"\n",
    "            grad_input = grad_input*(1-i)\n",
    "            return grad_input, grad_alpha\n",
    "\n",
    "    return _pq().apply\n",
    "\n",
    "class weight_quantize_fn(nn.Module):\n",
    "    def __init__(self, w_bit):\n",
    "        super(weight_quantize_fn, self).__init__()\n",
    "        self.w_bit = w_bit-1\n",
    "        #self.wgt_alpha = wgt_alpha\n",
    "        self.weight_q = weight_quantization(b=self.w_bit)\n",
    "        #self.register_parameter('wgt_alpha', Parameter(torch.tensor(3.0)))\n",
    "    def forward(self, weight):\n",
    "        #mean = weight.data.mean()\n",
    "        #std = weight.data.std()\n",
    "        #weight = weight.add(-mean).div(std)      # weights normalization\n",
    "        weight_q = self.weight_q(weight, self.wgt_alpha)\n",
    "\n",
    "        return weight_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_alpha=1\n",
    "w_bits=16\n",
    "weight_quant = weight_quantize_fn(w_bit= w_bits)  ## define quant function\n",
    "weight_quant.wgt_alpha = w_alpha\n",
    "fc1_quant      = weight_quant(net[0].weight)\n",
    "w_delta        = w_alpha/(2**(w_bits-1)-1)\n",
    "fc1_int        = fc1_quant/w_delta\n",
    "print(\"FC1 Weights: \\n\",fc1_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c401c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for layer in net:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "                layer.weight = Parameter(weight_quant(layer.weight))\n",
    "                w_delta = w_alpha/(2**(w_bits-1)-1)\n",
    "                layer.weight = Parameter(layer.weight/w_delta)\n",
    "                layer.bias = Parameter(layer.bias/w_delta)\n",
    "#                 print(layer.weight)\n",
    "#                 print(layer.bias)\n",
    "        if isinstance(layer, torch.nn.Conv2d):\n",
    "                layer.weight = Parameter(weight_quant(layer.weight))\n",
    "                w_delta = w_alpha/(2**(w_bits-1)-1)\n",
    "                layer.weight = Parameter(layer.weight/w_delta)\n",
    "                layer.bias = Parameter(layer.bias/w_delta)\n",
    "#                 print(layer.weight)\n",
    "#                 print(layer.bias)\n",
    "        if isinstance(layer, snn.Leaky):\n",
    "                layer.threshold = layer.threshold/w_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = batch_accuracy(test_loader, net, num_steps, batch_size)\n",
    "\n",
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({'state_dict': net.state_dict(),}, 1, fdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86841624",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = '/Volumes/export/isn/keli/Desktop/CRI/result/model_quantized.pth.tar'\n",
    "checkpoint = torch.load(best_model_path)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286d4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = batch_accuracy(test_loader, net, num_steps, batch_size)\n",
    "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6820f",
   "metadata": {},
   "source": [
    "### Mapping into CRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(net):\n",
    "    if i % 2 == 0:\n",
    "        print(layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30db36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weights and bias for torchsnn\n",
    "layers, biases = [], []\n",
    "for i, layer in enumerate(net):\n",
    "    if i % 2 == 0:\n",
    "        layers.append(layer.weight.detach().cpu().numpy())\n",
    "        biases.append(layer.bias.detach().cpu().numpy())\n",
    "\n",
    "print(np.min(layers[1]))\n",
    "print(np.max(layers[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103031dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layerNum, layer in enumerate(layers):\n",
    "    print(layer.shape)\n",
    "    print(biases[layerNum].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ed87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "axonsDict = {}\n",
    "neuronsDict = {}\n",
    "outputs = []\n",
    "bias_axon = {}\n",
    "\n",
    "axonOffset = 0\n",
    "currLayerNeuronIdxOffset = 0\n",
    "nextLayerNeuronIdxOffset = 0\n",
    "for layerNum, layer in enumerate(layers):\n",
    "    inFeatures = layer.shape[1]\n",
    "    outFeatures = layer.shape[0]\n",
    "    shape = layer.shape\n",
    "    weight = layer\n",
    "    bias = biases[layerNum]\n",
    "    print(\"Weights shape: \", np.shape(weight))\n",
    "    if (layerNum == 0):\n",
    "        print('constructing Axons')\n",
    "        print(\"Input layer shape(outfeature, infeature): \", weight.shape)\n",
    "        for axonIdx, axon in enumerate(weight.T):\n",
    "            #print(axonIdx)\n",
    "            axonID = 'a'+str(axonIdx)\n",
    "            axonEntry = [(str(postSynapticID), int(synapseWeight)) for postSynapticID, synapseWeight in enumerate(axon) ]\n",
    "            axonsDict[axonID] = axonEntry\n",
    "        axonOffset += inFeatures\n",
    "        print(\"axon offset: \",axonOffset)\n",
    "        #implmenting bias: for each bias add a axon with corresponding weights with synapse (neuron, bias_val)\n",
    "        print('Construct bias axons for first hidden layers:',bias.shape)\n",
    "        for neuronIdx, bias_value in enumerate(bias):\n",
    "            biasAxonID = 'a'+str(neuronIdx + axonOffset)\n",
    "            biasAxonEntry = [(str(neuronIdx),int(bias_value))]\n",
    "            axonsDict[biasAxonID] = biasAxonEntry\n",
    "        print(\"number of axons: \", len(axonsDict))\n",
    "        print(\"number of neurons: \", len(neuronsDict),\"\\n\")\n",
    "        \n",
    "    elif (layerNum == len(layers)-1):\n",
    "        print('constructing output layer')\n",
    "        nextLayerNeuronIdxOffset += inFeatures\n",
    "        print(\"output layer shape(outfeature, infeature): \", weight.shape)\n",
    "        for baseNeuronIdx, neuron in enumerate(weight.T):\n",
    "            neuronID = str(baseNeuronIdx+currLayerNeuronIdxOffset)\n",
    "            neuronEntry = [(str(basePostSynapticID+nextLayerNeuronIdxOffset), int(synapseWeight)) for basePostSynapticID, synapseWeight in enumerate(neuron) if synapseWeight != 0]\n",
    "            neuronsDict[neuronID] = neuronEntry\n",
    "            #print(neuronID)\n",
    "        currLayerNeuronIdxOffset += inFeatures\n",
    "        #instantiate the output neurons\n",
    "        print('instantiate output neurons')\n",
    "        for baseNeuronIdx in range(outFeatures):\n",
    "            neuronID = str(baseNeuronIdx+nextLayerNeuronIdxOffset)\n",
    "            neuronsDict[neuronID] = []\n",
    "            outputs.append(neuronID)\n",
    "            #print(neuronID)\n",
    "        #implmenting bias: for each bias add a axon with corresponding weights with synapse (neuron, bias_val)\n",
    "        print('Construct bias axons for output neurons',bias.shape)\n",
    "        axonOffset += inFeatures\n",
    "        for neuronIdx, bias_value in enumerate(bias):\n",
    "            biasAxonID = 'a'+str(neuronIdx + axonOffset)\n",
    "            biasAxonEntry = [(str(neuronIdx+nextLayerNeuronIdxOffset),int(bias_value))]\n",
    "            axonsDict[biasAxonID] = biasAxonEntry\n",
    "        print(\"number of axons: \", len(axonsDict))\n",
    "        print(\"number of neurons: \", len(neuronsDict),\"\\n\")\n",
    "            \n",
    "    else:\n",
    "        print('constructing hidden layer')\n",
    "        nextLayerNeuronIdxOffset += inFeatures\n",
    "        for baseNeuronIdx, neuron in enumerate(weight.T): #SHOULD THIS BE A TRANSPOSE\n",
    "            neuronID = str(baseNeuronIdx+currLayerNeuronIdxOffset)\n",
    "            neuronEntry = [(str(basePostSynapticID+nextLayerNeuronIdxOffset), int(synapseWeight)) for basePostSynapticID, synapseWeight in enumerate(neuron) if synapseWeight != 0 ]\n",
    "            neuronsDict[neuronID] = neuronEntry\n",
    "            #print(neuronID)\n",
    "        currLayerNeuronIdxOffset += inFeatures\n",
    "        axonOffset += inFeatures\n",
    "        print(\"axon offset: \",axonOffset)\n",
    "        #implmenting bias: for each bias add a axon with corresponding weights with synapse (neuron, bias_val)\n",
    "        print('Construct bias axons for hidden layers:',bias.shape)\n",
    "        for neuronIdx, bias_value in enumerate(bias):\n",
    "            biasAxonID = 'a'+str(neuronIdx + axonOffset)\n",
    "            biasAxonEntry = [(str(neuronIdx+nextLayerNeuronIdxOffset),int(bias_value))]\n",
    "            axonsDict[biasAxonID] = biasAxonEntry\n",
    "        print(\"number of axons: \", len(axonsDict))\n",
    "        print(\"number of neurons: \", len(neuronsDict),\"\\n\")\n",
    "        \n",
    "print(\"output neurons: \", outputs)\n",
    "print(\"number of axons: \", len(axonsDict))\n",
    "print(\"number of neurons: \", len(neuronsDict),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of axons: \",len(axonsDict))\n",
    "totalAxonSyn = 0\n",
    "maxFan = 0\n",
    "for key in axonsDict.keys():\n",
    "    totalAxonSyn += len(axonsDict[key])\n",
    "    if len(axonsDict[key]) > maxFan:\n",
    "        maxFan = len(axonsDict[key])\n",
    "print(\"Total number of connections between axon and neuron: \", totalAxonSyn)\n",
    "print(\"Max fan out of axon: \", maxFan)\n",
    "print('---')\n",
    "print(\"Number of neurons: \", len(neuronsDict))\n",
    "totalSyn = 0\n",
    "maxFan = 0\n",
    "for key in neuronsDict.keys():\n",
    "    totalSyn += len(neuronsDict[key])\n",
    "    if len(neuronsDict[key]) > maxFan:\n",
    "        maxFan = len(neuronsDict[key])\n",
    "print(\"Total number of connections between hidden and output layers: \", totalSyn)\n",
    "print(\"Max fan out of neuron: \", maxFan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2s.api import CRI_network\n",
    "import cri_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a46816",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['neuron_type'] = \"I&F\"\n",
    "config['global_neuron_params'] = {}\n",
    "config['global_neuron_params']['v_thr'] = 9*10**4\n",
    "#softwareNetwork = CRI_network(axons=axonsDict,connections=neuronsDict,config=config,target='simpleSim', outputs = outputs)\n",
    "hardwareNetwork = CRI_network(axons=axonsDict,connections=neuronsDict,config=config,target='CRI', outputs = outputs,simDump = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_CRI(currentInput):\n",
    "    num_steps = 10\n",
    "    currentInput = data.view(data.size(0), -1)\n",
    "    batch = []\n",
    "    n = 0\n",
    "    for element in currentInput:\n",
    "        timesteps = []\n",
    "        rateEnc = spikegen.rate(element,num_steps)\n",
    "        rateEnc = rateEnc.detach().cpu().numpy()\n",
    "        for element in rateEnc:\n",
    "            currInput = ['a'+str(idx) for idx,axon in enumerate(element) if axon != 0]\n",
    "            biasInput = ['a'+str(idx) for idx in range(784,len(axonsDict))]\n",
    "#             timesteps.append(currInput)\n",
    "#             timesteps.append(biasInput)\n",
    "            timesteps.append(currInput+biasInput)\n",
    "        batch.append(timesteps)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CRI(inputList,output_offset):\n",
    "    predictions = []\n",
    "    total_time_cri = 0\n",
    "    #each image\n",
    "    for currInput in inputList:\n",
    "        #reset the membrane potential to zero\n",
    "        softwareNetwork.simpleSim.initialize_sim_vars(len(neuronsDict))\n",
    "        spikeRate = [0]*10\n",
    "        #each time step\n",
    "        for slice in currInput:\n",
    "            start_time = time.time()\n",
    "            swSpike = softwareNetwork.step(slice, membranePotential=False)\n",
    "            end_time = time.time()\n",
    "            total_time_cri = total_time_cri + end_time-start_time\n",
    "            for spike in swSpike:\n",
    "                spikeIdx = int(spike) - output_offset \n",
    "                try: \n",
    "                    if spikeIdx >= 0: \n",
    "                        spikeRate[spikeIdx] += 1 \n",
    "                except:\n",
    "                    print(\"SpikeIdx: \", spikeIdx,\"\\n SpikeRate:\",spikeRate )\n",
    "        predictions.append(spikeRate.index(max(spikeRate)))\n",
    "    print(f\"Total simulation execution time: {total_time_cri:.5f} s\")\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CRI_hw(inputList,output_offset):\n",
    "    predictions = []\n",
    "    #each image\n",
    "    total_time_cri = 0\n",
    "    for currInput in inputList:\n",
    "        #initiate the softwareNetwork for each image\n",
    "        cri_simulations.FPGA_Execution.fpga_controller.clear(len(neuronsDict), False, 0)  ##Num_neurons, simDump, coreOverride\n",
    "        spikeRate = [0]*10\n",
    "        #each time step\n",
    "        for slice in currInput:\n",
    "            start_time = time.time()\n",
    "            hwSpike = hardwareNetwork.step(slice, membranePotential=False)\n",
    "#             print(\"Mem:\",mem)\n",
    "            end_time = time.time()\n",
    "            total_time_cri = total_time_cri + end_time-start_time\n",
    "            print(hwSpike)\n",
    "            for spike in hwSpike:\n",
    "                print(int(spike))\n",
    "                spikeIdx = int(spike) - output_offset \n",
    "                if spikeIdx >= 0: \n",
    "                    spikeRate[spikeIdx] += 1 \n",
    "        predictions.append(spikeRate.index(max(spikeRate))) \n",
    "    print(f\"Total execution time CRIFPGA: {total_time_cri:.5f} s\")\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c78aec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "cri_correct = 0\n",
    "cri_correct_hw = 0\n",
    "batch_size = 10\n",
    "# drop_last switched to False to keep all samples\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "output_offset = 7500\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    \n",
    "    train_loader = iter(train_loader)\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        input = input_to_CRI(data)\n",
    "#         criPred = torch.tensor(run_CRI(input,output_offset)).to(device)\n",
    "#         print(\"CRI Predicted: \",criPred)\n",
    "        criPred_hw = torch.tensor(run_CRI_hw(input,output_offset)).to(device)\n",
    "        print(\"CRI Predicted HW: \",criPred_hw)\n",
    "        print(\"Target: \",targets)\n",
    "        test_spk, _ = forward_pass(net, num_steps, data, batch_size)\n",
    "\n",
    "        # calculate total accuracy\n",
    "        _, predicted = test_spk.sum(dim=0).max(1)\n",
    "        print(\"Torchsnn Predicted: \",predicted)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "#         cri_correct += (criPred == targets).sum().item()\n",
    "        cri_correct_hw += (criPred_hw == targets).sum().item()\n",
    "        break #run for one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Totoal execution time: {end_time-start_time:.2f} s\")\n",
    "# print(f\"Total correctly classified test set images for TorchSNN: {correct}/{total}\")\n",
    "print(f\"Total correctly classified test set images for CRI: {cri_correct}/{total}\")\n",
    "print(f\"Test Set Accuracy for TorchSNN: {100 * correct / total:.2f}%\")\n",
    "print(f\"Test Set Accuracy for CRI: {100 * cri_correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349797c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "782c4fc05a7b0c5006502edc276c124083adbfff5066531c0f613c007bf9a5ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
